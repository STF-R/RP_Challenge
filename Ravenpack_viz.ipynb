{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Presentation of the challenge](#1) <br>\n",
    "- [1.1 - The RavenPack Data Science Challenge](#1.1) <br>\n",
    "- [1.2 - Overview of the approach](#1.2)<br><br>\n",
    "\n",
    "[2. Collect & transform data](#2) <br>\n",
    "- [2.1 - Connection à SQL Server](#2.1) <br>\n",
    "- [2.2 - Mise au format des données](#2.2)<br>\n",
    "- [](#2.3)<br>\n",
    "- [](#2.4)<br>\n",
    "- [](#2.5)<br>\n",
    "\n",
    "[3. Descriptive analysis / Statistical inferences](#3) <br>\n",
    "- [](#3.1)<br>\n",
    "- [](#3.2)<br>\n",
    "- [](#3.3)<br>\n",
    "- [](#3.4)<br>\n",
    "\n",
    "[4. Preprocess the data](#4) <br>\n",
    "- [4.1 - Clustering](#4.1)<br>\n",
    "- [4.2 - Création de la target (y)](#4.2)<br>\n",
    "- [4.3 - Valeurs aberrantes](#4.3)<br>\n",
    "- [4.4 - One-hot-encoding](#4.4)<br><br>\n",
    "\n",
    "[5. Create features](#5) <br>\n",
    "- [5.1 - Dataset du modèle 1](#5.1)<br>\n",
    "- [](#5.2)<br>\n",
    "- [](#5.3)<br>\n",
    "- [](#5.4)<br>\n",
    "\n",
    "[6. Select a ML algo](#6) <br>\n",
    "- [6.1 - Dataset du modèle 1](#6.1)<br>\n",
    "- [](#6.2)<br>\n",
    "- [](#6.3)<br>\n",
    "- [](#6.4)<br>\n",
    "\n",
    "[7. Backtest on unseen data](#7) <br>\n",
    "- [7.1 - Dataset du modèle 1](#7.1)<br>\n",
    "- [](#7.2)<br>\n",
    "- [](#7.3)<br>\n",
    "- [](#7.4)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# <a id =1> </a>  **1. Presentation of the challenge**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 <a id =1.1> </a>The RavenPack Data Science Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Dataset (in csv format) with the following structure (column wise):\n",
    "\n",
    "<br>\n",
    "\n",
    "| label : | 'description' |\n",
    "| ----------- | ----------- |\n",
    "| DATE | A given date |\n",
    "|  RP_ENTITY_ID | An asset ID |\n",
    "|  T0_RETURN | Return on the given date |\n",
    "|  T1_RETURN |  Next day Return |\n",
    "|  A set of 36 different Indicators |  (Features) |\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"border: 0px ridge white;\n",
    "          color: color_police;\n",
    "          background-color: colr;\n",
    "          padding: 5rem;\n",
    "          display: flex;\n",
    "          flex-direction: column;\n",
    "          font: small-caps bold 2rem sans-serif;\n",
    "          text-align: justify;\">\n",
    "The aim of this project is to come up with a model/algorithm to produce predictions on T1_RETURN using the available information.\n",
    "    <br><br>\n",
    "You are expected to use said predictions to form a portfolio that will then be evaluated according to Information Ratio.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**As an output, you are asked to provide:**\n",
    "\n",
    "- A short report on what you have done together with some results and conclusions, including a performance comparison among the models you propose, using Information Ratio as a metric.\n",
    "\n",
    "- The source code used for producing your analysis and results.\n",
    "\n",
    "<br><br>\n",
    "The project will allow us to evaluate your skill set within programming, data preparation, modeling, and communication. \n",
    "\n",
    "<br><br>\n",
    "links to the files :\n",
    "\n",
    "https://drive.google.com/a/rav...\n",
    "\n",
    "https://drive.google.com/a/rav..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><code>\n",
    "#################################\n",
    "#######  SAMPLE CODE   ##########\n",
    "#################################\n",
    "library(data.table)\n",
    "# Open CSV file and convert to data table*\n",
    "# Full path to your csv file\n",
    "fullPath = \\<The path to the provided csv file goes here>\n",
    "DataSet = data.table(read.csv(file = fullPath))\n",
    "# We have a panel data.table with information about dates, Entity IDs, Returns (T1 and T0), and 36 different indicators).\n",
    "\n",
    "\n",
    "### Example on how to check the performance of a given prediction.\n",
    "# Lets say we are using the sign of an indicator(GROUP_E_ALL_SG90) as predictor\n",
    "# We select only the data we are interested in\n",
    "PredictionData = subset(DataSet, select = c('DATE', 'RP_ENTITY_ID','GROUP_E_ALL_SG90', 'T1_RETURN'))\n",
    "# We drop NA's\n",
    "PredictionData = PredictionData[complete.cases(PredictionData)]\n",
    "# We get unique rows\n",
    "PredictionData = unique(PredictionData)\n",
    "# We sort by DATE, setting its key\n",
    "setkey(PredictionData,'DATE')\n",
    "# Compute Average Return per day using the sign of the indicator as predictor*\n",
    "PredictionData[, AVGRET:= mean(sign(GROUP_E_ALL_SG90)*T1_RETURN,na.rm = TRUE), by = c('DATE')]\n",
    "Results = subset(PredictionData,select = c('DATE','AVGRET'))\n",
    "Results = unique(Results)\n",
    "# We plot the Cummulative Log Returns\n",
    "plot( as.Date(Results$DATE), cumsum(log(Results$AVGRET+1)), t = 'l', col = 'blue', ylab = 'Cummulative Return', xlab = 'DATE')\n",
    "\n",
    "\n",
    "### Some Stats\n",
    "# AnnualizedReturn\n",
    "AnnualizedReturn = mean(log(Results$AVGRET+1))*252\n",
    "# AnnualizedVolatility\n",
    "AnnualizedVolatility = sqrt(var(log(Results$AVGRET+1)))*sqrt(252)\n",
    "# Information Ratio \n",
    "InformationRatio = AnnualizedReturn/AnnualizedVolatility\n",
    "title(paste('Return Profile - Information Ratio', round(InformationRatio,2)))\n",
    "\n",
    "</code>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id =1.2> </a> 1.2 Overview of the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# <a id =2> </a> **2. Collect & transform data**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from IPython.core.display import display, HTML\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tslearn.utils import to_time_series_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.neighbors import (KNeighborsClassifier, \n",
    "                               KNeighborsRegressor)\n",
    "from sklearn.model_selection import (cross_val_score, \n",
    "                                     cross_val_predict, \n",
    "                                     GridSearchCV)\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "# from yellowbrick.model_selection import ValidationCurve, LearningCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<style> *{margin:0; padding:0;} html, body, \\\n",
    "             .container{margin:2;!important padding:0;!important} \\\n",
    "             .container { width:100% !important;}</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../SampleDataSet.csv')\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "descr = df.describe()\n",
    "df = df.groupby(['RP_ENTITY_ID', 'DATE'], as_index=False).first()\n",
    "###col with 100% NA\n",
    "cols_to_drop = descr.columns[descr.loc['count',:]==0]\n",
    "###delete these cols\n",
    "df = df.loc[:, ~df.columns.isin(cols_to_drop)]\n",
    "q = 0.9995\n",
    "df = df.loc[ (df['T0_RETURN']<df['T0_RETURN'].quantile(q)) \n",
    "            & (df['T0_RETURN']>df['T0_RETURN'].quantile(1-q)) \n",
    "            & (df['T1_RETURN']<df['T1_RETURN'].quantile(q)) \n",
    "            & (df['T1_RETURN']>df['T1_RETURN'].quantile(1-q)) ]\n",
    "\n",
    "ret = 0.01\n",
    "perf_range = (df['T1_RETURN']>=ret) | (df['T1_RETURN']<=-ret)\n",
    "df_perf = df.loc[ perf_range ]\n",
    "\n",
    "nb_date_ceil = 10000\n",
    "nb_date_floor = 756 #3y track record\n",
    "list_asset = df.RP_ENTITY_ID.value_counts().loc[(df.RP_ENTITY_ID.value_counts()<nb_date_ceil)&(df.RP_ENTITY_ID.value_counts()>nb_date_floor)].index\n",
    "list_asset = list(list_asset)\n",
    "\n",
    "df_track_perf = df_perf.loc[df_perf['RP_ENTITY_ID'].isin(list_asset),:]\n",
    "# df_track_perf.describe()\n",
    "\n",
    "df_track_perf['T0_RETURN_log'] = np.log(1+df_track_perf.loc[:,'T0_RETURN'].copy()) ##use log return\n",
    "df_track_perf['T1_RETURN_log'] = np.log(1+df_track_perf.loc[:,'T1_RETURN'].copy()) ##use log return\n",
    "cols_to_drop = ['T0_RETURN', 'T1_RETURN']\n",
    "df_track_perf = df_track_perf.loc[:, ~df_track_perf.columns.isin(cols_to_drop)]\n",
    "\n",
    "df_track_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.RP_ENTITY_ID.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###number of rows when selecting assets with a track record > 3 years\n",
    "# nb_assets = (df.RP_ENTITY_ID.value_counts()>=0).sum()\n",
    "# nb_assets_3y = (df.RP_ENTITY_ID.value_counts()>756).sum()\n",
    "# df.RP_ENTITY_ID.value_counts()[:-(nb_assets-nb_assets_3y)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:,:].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:,:].isna().sum(axis=0)/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# <a id =3> </a> **3. Descriptive analysis / Statistical inferences**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.figure(figsize=(15,10))\n",
    "# data = df.loc[:,:].isna().melt(value_name=\"missing\")\n",
    "# sorter = data.groupby('variable').sum().sort_values(by=['missing'], ascending=True).index.to_list()\n",
    "# data.variable = data.variable.astype(\"category\")\n",
    "# data.variable.cat.set_categories(sorter, inplace=True)\n",
    "# data = data.sort_values([\"variable\"])\n",
    "# ax = sns.displot(\n",
    "#     data=data,\n",
    "#     y=\"variable\",\n",
    "#     hue=\"missing\",\n",
    "#     multiple=\"fill\",\n",
    "#     aspect=1.25\n",
    "# )\n",
    "# # plt.legend(data['missing'].unique(), loc='lower left', bbox_to_anchor=(0, 1), facecolor='w', edgecolor='w')\n",
    "# ax.fig.set_size_inches(20,10)\n",
    "# plt.title('Total', fontsize=18, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')\n",
    "# plt.xlabel('count', fontsize=16, c='w')\n",
    "# plt.ylabel('feature', fontsize=16, c='w')\n",
    "# plt.legend(fontsize=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(35, 10))\n",
    "# corr = df.iloc[:,2:].isna().corr()\n",
    "\n",
    "# mask = np.zeros_like(corr, dtype=np.bool)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# cmap=sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5});\n",
    "# plt.title('Correl missing values', fontsize=18, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing value: no evident temporal structure (date, day, month, year)\n",
    "### MNAR Missing not at random (also known as nonignorable nonresponse) is data that is neither MAR nor MCAR (i.e. the value of the variable that's missing is related to the reason it's missing)\n",
    "### Generally speaking, there are 3 main approaches to handle missing data: \n",
    "#### (1) Imputation—where values are filled in the place of missing data, \n",
    "#### (2) omission—where samples with invalid data are discarded from further analysis,\n",
    "#### (3) analysis—by directly applying methods unaffected by the missing values. \n",
    "    \n",
    "    \n",
    "    \n",
    "###Imputations with RF are good for strong non-linear relationships between continuous variables and when there are interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,10))\n",
    "# sns.heatmap(df.iloc[:,2:-2].isna().transpose(),\n",
    "#             cmap=\"YlGnBu\",\n",
    "#             cbar_kws={'label': 'Missing Data'})\n",
    "# # ax.fig.set_size_inches(35,12)\n",
    "# plt.title('Total', fontsize=18, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,10))\n",
    "# sorted_df = df.sort_values(by=['GLOBAL_HEAD', 'GLOBAL_BODY'], ascending=True)\n",
    "# sns.heatmap(sorted_df.iloc[:,2:-2].isna().transpose(),\n",
    "#             cmap=\"YlGnBu\",\n",
    "#             cbar_kws={'label': 'Missing Data'})\n",
    "# # ax.fig.set_size_inches(35,12)\n",
    "# plt.title(\"sorted by=['GLOBAL_HEAD', 'GLOBAL_BODY']\", fontsize=18, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,10))\n",
    "# sorted_df = df.sort_values(by=['GLOBAL_HEAD'], ascending=True)\n",
    "# sns.heatmap(sorted_df.iloc[:,2:-2].isna().transpose(),\n",
    "#             cmap=\"YlGnBu\",\n",
    "#             cbar_kws={'label': 'Missing Data'})\n",
    "# # ax.fig.set_size_inches(35,12)\n",
    "# plt.title(\"sorted by=['GLOBAL_HEAD', 'GLOBAL_BODY']\", fontsize=18, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,10))\n",
    "# sorted_df = df.sort_values(by=['GLOBAL_BODY'], ascending=True)\n",
    "# sns.heatmap(sorted_df.iloc[:,2:-2].isna().transpose(),\n",
    "#             cmap=\"YlGnBu\",\n",
    "#             cbar_kws={'label': 'Missing Data'})\n",
    "# # ax.fig.set_size_inches(35,12)\n",
    "# plt.title(\"sorted by=['GLOBAL_HEAD', 'GLOBAL_BODY']\", fontsize=18, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,10))\n",
    "# sorted_df = df.sort_values(by=['GROUP_A_ALL'], ascending=True)\n",
    "# sns.heatmap(sorted_df.iloc[:,2:-2].isna().transpose(),\n",
    "#             cmap=\"YlGnBu\",\n",
    "#             cbar_kws={'label': 'Missing Data'})\n",
    "# # ax.fig.set_size_inches(35,12)\n",
    "# plt.title(\"sorted by=['GLOBAL_HEAD', 'GLOBAL_BODY']\", fontsize=18, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,10))\n",
    "# sorted_df = df.sort_values(by=['GROUP_E_ALL'], ascending=True)\n",
    "# sns.heatmap(sorted_df.iloc[:,2:-2].isna().transpose(),\n",
    "#             cmap=\"YlGnBu\",\n",
    "#             cbar_kws={'label': 'Missing Data'})\n",
    "# # ax.fig.set_size_inches(35,12)\n",
    "# plt.title(\"sorted by=['GLOBAL_HEAD', 'GLOBAL_BODY']\", fontsize=18, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y1 = pd.DataFrame(pd.DataFrame(dico_y['optim'])['y1'])\n",
    "# slots = pd.DataFrame(dico_y_slot['optim'])[1:-1]\n",
    "# data_pairplot = pd.merge(y1, slots, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby(['DATE','RP_ENTITY_ID'], as_index=False).first()\n",
    "# df = df.groupby(['RP_ENTITY_ID', 'DATE'], as_index=False).first()\n",
    "\n",
    "# # df.sort_values(by=['RP_ENTITY_ID','DATE'])\n",
    "# df = pd.read_csv('../SampleDataSet.csv')\n",
    "# df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "# df = df.groupby(['RP_ENTITY_ID', 'DATE'], as_index=False).first()\n",
    "# ###col with 100% NA\n",
    "# cols_to_drop = descr.columns[descr.loc['count',:]==0]\n",
    "# ###delete these cols\n",
    "# df = df.loc[:, ~df.columns.isin(cols_to_drop)]\n",
    "\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(35, 10))\n",
    "# corr = df.iloc[:,2:].corr()\n",
    "\n",
    "# mask = np.zeros_like(corr, dtype=np.bool)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# cmap=sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../SampleDataSet.csv')\n",
    "# df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "# df = df.groupby(['RP_ENTITY_ID', 'DATE'], as_index=False).first()\n",
    "# ###col with 100% NA\n",
    "# cols_to_drop = descr.columns[descr.loc['count',:]==0]\n",
    "# ###delete these cols\n",
    "# df = df.loc[:, ~df.columns.isin(cols_to_drop)]\n",
    "\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(35, 10))\n",
    "# retained_cols = ['GROUP_A_ALL','GROUP_A_HEAD','GROUP_A_BODY','GROUP_E_ALL','GROUP_E_HEAD','T0_RETURN', 'T1_RETURN']\n",
    "\n",
    "# dfna = df.dropna()\n",
    "# corr = dfna.iloc[:,2:].corr()\n",
    "\n",
    "# mask = np.zeros_like(corr, dtype=np.bool)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# cmap=sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = data_pairplot.corr()\n",
    "# corr.style.background_gradient(cmap='coolwarm').set_precision(2).set_properties(**{'font-size': '12pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.PairGrid(df.iloc[0:500,2:-2])\n",
    "# g.map_diag(sns.histplot)\n",
    "# g.map_offdiag(sns.scatterplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = df.columns[2:]\n",
    "\n",
    "# fig = plt.figure(figsize=(25, 15))\n",
    "# fig.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "# for i,col in enumerate(cols):\n",
    "#     ax = fig.add_subplot(8, 4, i+1)\n",
    "#     sns.histplot(df[col], ax=ax)\n",
    "# plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['T0_RETURN','T1_RETURN']\n",
    "\n",
    "# fig = plt.figure(figsize=(20, 10))\n",
    "# fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "# for i,col in enumerate(cols):\n",
    "#     ax = fig.add_subplot(1, 2, i+1)\n",
    "#     sns.histplot(df[col], ax=ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = 0.9995\n",
    "# descr_qsplit = np.concatenate(([1-q], np.arange(0.05,0.95,0.05), [q]), axis=0)\n",
    "# df[['T0_RETURN','T1_RETURN']].describe(descr_qsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import seaborn as sns\n",
    "# sns.set(rc = {'figure.figsize':(15,8)})\n",
    "# ax = sns.violinplot(data=df[[\"T0_RETURN\",\"T1_RETURN\"]], orient=\"v\", palette=\"Set2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = 0.9995\n",
    "# df_violin = pd.DataFrame()\n",
    "# df_violin['T0_RETURN'] = df['T0_RETURN'].loc[ (df['T0_RETURN']<df['T0_RETURN'].quantile(q)) & (df['T0_RETURN']>df['T0_RETURN'].quantile(1-q)) ]\n",
    "# df_violin['T1_RETURN'] = df['T1_RETURN'].loc[ (df['T1_RETURN']<df['T1_RETURN'].quantile(q)) & (df['T1_RETURN']>df['T1_RETURN'].quantile(1-q)) ]\n",
    "\n",
    "# ax = sns.violinplot(data=df_violin[[\"T0_RETURN\",\"T1_RETURN\"]], orient=\"v\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = 0.9995\n",
    "# df = df.loc[ (df['T0_RETURN']<df['T0_RETURN'].quantile(q)) \n",
    "#             & (df['T0_RETURN']>df['T0_RETURN'].quantile(1-q)) \n",
    "#             & (df['T1_RETURN']<df['T1_RETURN'].quantile(q)) \n",
    "#             & (df['T1_RETURN']>df['T1_RETURN'].quantile(1-q)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_melted = pd.melt(df[['T0_RETURN', 'T1_RETURN']])\n",
    "# # df_melted = df_melted.loc[(df_melted['value']<=-0.005)|(df_melted['value']>=0.005)]\n",
    "# # df_melted_log = pd.DataFrame()\n",
    "# # df_melted_log['variable'] = df_melted['variable'] \n",
    "# # df_melted_log['value'] = np.log(1+df_melted['value'])\n",
    "\n",
    "# ax = sns.displot(df_melted, x=\"value\", hue=\"variable\", kind=\"kde\", fill=True)\n",
    "# ax.fig.set_size_inches(15,5)\n",
    "# sns.move_legend(\n",
    "#     ax, \"left\",\n",
    "#     bbox_to_anchor=(0.465, 0.98), ncol=3, title=None, frameon=False,\n",
    "# )\n",
    "# plt.title('T0 and T1 density', fontsize=18, color='w')\n",
    "# plt.xlabel('value', fontsize=16, color='w')\n",
    "# plt.ylabel('density', fontsize=16, color='w')\n",
    "# plt.tick_params(axis='x', colors='w')\n",
    "# plt.tick_params(axis='y', colors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = 0.02\n",
    "perf_range = (df['T1_RETURN']>=ret) | (df['T1_RETURN']<=-ret)\n",
    "df_perf = df.loc[ perf_range ]\n",
    "df_perf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_date_ceil = 10000\n",
    "nb_date_floor = 504 #3y track record\n",
    "list_asset = df.RP_ENTITY_ID.value_counts().loc[(df.RP_ENTITY_ID.value_counts()<nb_date_ceil)&(df.RP_ENTITY_ID.value_counts()>nb_date_floor)].index\n",
    "list_asset = list(list_asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_track_perf['T0_RETURN_log'] = np.log(1+df_track_perf.loc[:,'T0_RETURN'].copy()) ##use log return\n",
    "df_track_perf['T1_RETURN_log'] = np.log(1+df_track_perf.loc[:,'T1_RETURN'].copy()) ##use log return\n",
    "cols_to_drop = ['T0_RETURN', 'T1_RETURN']\n",
    "df_track_perf = df_track_perf.loc[:, ~df_track_perf.columns.isin(cols_to_drop)]\n",
    "\n",
    "X_all = df_track_perf.iloc[:,2:-1]\n",
    "y = df_track_perf.T1_RETURN_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bivariate Scatter Plots\n",
    "sns.set_style('whitegrid')\n",
    "g = sns.pairplot(X_all.iloc[:,:10].assign(T1_RETURN_log=y), y_vars=['T1_RETURN_log'], x_vars=X_all.columns[:10])\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bivariate Scatter Plots\n",
    "g = sns.pairplot(X_all.iloc[:,10:20].assign(T1_RETURN_log=y), y_vars=['T1_RETURN_log'], x_vars=X_all.columns[10:20])\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bivariate Scatter Plots\n",
    "g = sns.pairplot(X_all.iloc[:,20:].assign(T1_RETURN_log=y), y_vars=['T1_RETURN_log'], x_vars=X_all.columns[20:])\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "correl = X_all.apply(lambda x: spearmanr(x, y)[0])\n",
    "correl.sort_values().plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = '2005-01-03'\n",
    "freq = 'D'\n",
    "# alpha=0.1\n",
    "\n",
    "fig = go.Figure()\n",
    "for asset in list_asset:\n",
    "    df2 = df.query(\"RP_ENTITY_ID==@asset\")#['DATE'].loc['2005-01-03':, :]\n",
    "    df2 = df2[df2['DATE']>=beg]\n",
    "    df2['PRICE'] = 100*(1 + df2['T0_RETURN']).cumprod()\n",
    "    df2['PRICE'] = df2['PRICE'].shift(1)\n",
    "#     df2['T0_RETURN_log'] = np.log(1+df2['T0_RETURN'])\n",
    "#     df2['PRICE'] = np.exp(df2['T0_RETURN_log']).cumprod()*100\n",
    "    df2 = df2.loc[:,['DATE','PRICE', 'RP_ENTITY_ID']]\n",
    "    df2 = df2.set_index('DATE')\n",
    "    df2 = df2.resample(freq).mean()\n",
    "#     df2 = df2.ewm(alpha=alpha).mean()\n",
    "    fig.add_traces(go.Scatter(x=df2.index, y=df2.PRICE, mode='lines', name = asset))\n",
    "    fig.update_yaxes(title_text=\"y-axis in logarithmic scale\", type=\"log\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = '2005-01-03'\n",
    "# freq = 'M'\n",
    "list_asset = [\n",
    "    '39BFF6', '0F0440', '940C3D', 'ACDF88', 'D54E62', '248F44', 'AA5C8E', 'D8442A', '1BC12C', '86A1B9', '061366', '228D42', '12A3A3', 'D33D8C',\n",
    "    'D4463B', 'A631A3', '3C7F5F', '168A5D', '33AD83', '1A3E1B', 'CA212F', '422CE3', '1FAF22', 'E08AF3', '5DD486', 'F4E882', '6203E4', 'D6EAA3', \n",
    "    'D75910', '9CA619', 'CFF15D', '4C6C63', '57DDB9', 'E68733', 'DCD97F', 'BE4F2F', '16B183', '88598A',    \n",
    "]\n",
    "fig = go.Figure()\n",
    "for asset in list_asset:\n",
    "    df2 = df.query(\"RP_ENTITY_ID==@asset\")#['DATE'].loc['2005-01-03':, :]\n",
    "    df2 = df2[df2['DATE']>=beg]\n",
    "    df2['PRICE'] = 100*(1 + df2['T0_RETURN']).cumprod()\n",
    "    df2['PRICE'] = df2['PRICE'].shift(1)\n",
    "    df2 = df2.loc[:,['DATE','PRICE', 'RP_ENTITY_ID']]\n",
    "    df2 = df2.set_index('DATE')\n",
    "#     df2 = df2.resample(freq).mean()\n",
    "    fig.add_traces(go.Scatter(x=df2.index, y=df2.PRICE, mode='lines', name = asset))\n",
    "    fig.update_yaxes(title_text=\"good predict\", type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
